{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh1V5+9hyKXtki3II5vIZs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniket-tempest/HAR-Employee-Identification/blob/main/HAR_MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk0U_G9BbIn9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XQrp7rqdhNz",
        "outputId": "249a90a9-cef2-469f-fd8d-8653b9a5d1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and Different Classifiers"
      ],
      "metadata": {
        "id": "UqypRGaBgPV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ntMDVkhgeZoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "BCgHGQthgBl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import different classifiers\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier"
      ],
      "metadata": {
        "id": "UrcqeWaagMw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "F-Qqb9JNgxsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file):\n",
        "    data = pd.read_csv(file)\n",
        "    \n",
        "    # suffle data\n",
        "    data = sklearn.utils.shuffle(data)\n",
        "    \n",
        "    X_data = data.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
        "    y_data = data.ActivityName\n",
        "    \n",
        "    return np.array(X_data), np.array(y_data)"
      ],
      "metadata": {
        "id": "Nv8J_82RgiPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_x, train_y, model_name='NB', validation=None):\n",
        "    \"\"\"\n",
        "    Possible model names: ['NB', 'SVM', 'XGB', 'MLP', 'ADA', 'BAG', 'RF']\n",
        "    default = 'NB'\n",
        "    \n",
        "    validation: (val_x, val_y) tupple for validation accuracy score.\n",
        "    \n",
        "    return: trained model\n",
        "    \"\"\"\n",
        "    model = None\n",
        "    if model_name == 'SVM':\n",
        "        model = svm.SVC(gamma='scale', probability=True)\n",
        "    elif model_name == 'XGB':\n",
        "        model = XGBClassifier(n_estimators=200, max_depth=5, n_jobs=2)\n",
        "#         model = XGBClassifier()\n",
        "    elif model_name == 'MLP':\n",
        "        model = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=800, alpha=0.0001,\n",
        "                     solver='sgd', verbose=10, tol=0.000000001)\n",
        "    elif model_name == 'ADA':\n",
        "        model = AdaBoostClassifier(n_estimators=50)\n",
        "    elif model_name == 'BAG':\n",
        "        model = BaggingClassifier(n_jobs=2, n_estimators=50)\n",
        "    elif model_name == 'RF':\n",
        "        model = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
        "    elif model_name == 'KNN':\n",
        "        model = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
        "    else:\n",
        "        model = GaussianNB()\n",
        "    \n",
        "    model.fit(train_x, train_y)\n",
        "    \n",
        "    if validation is not None:\n",
        "        y_hat = model.predict(validation[0])\n",
        "        acc = metrics.accuracy_score(validation[1], y_hat)\n",
        "        print(f\"Validation Accuracy in '{model_name}' = {acc}\")\n",
        "        cm = metrics.confusion_matrix(validation[1], y_hat)\n",
        "        print(cm)\n",
        "        recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
        "        precision = cm[0][0] / (cm[0][0] + cm[1][0])\n",
        "        f1 = 2*(precision*recall)/(precision+recall)\n",
        "        print(f\"Recall in '{model_name}' = {recall}\")\n",
        "        print(f\"Precision in '{model_name}' = {precision}\")\n",
        "        print(f\"F1 Score in '{model_name}' = {f1}\")\n",
        "               \n",
        "    return model"
      ],
      "metadata": {
        "id": "YLoydtqXg4Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Cells"
      ],
      "metadata": {
        "id": "EsUiDRJOhECx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y = read_data('drive/MyDrive/data/train.csv')\n",
        "test_X, test_y = read_data('drive/MyDrive/data/test.csv')"
      ],
      "metadata": {
        "id": "ROwCeyT7g_kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train  : \", train_X.shape, train_y.shape)\n",
        "print(\"Test   : \", test_X.shape, test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e21fCX9AhS-d",
        "outputId": "b4cfd608-d3ac-4b13-de15-5fffab5b3806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train  :  (7352, 561) (7352,)\n",
            "Test   :  (2947, 561) (2947,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw9IwwD6hTE_",
        "outputId": "7d986bfe-ab79-4151-92ce-d5eb658be15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['LAYING', 'LAYING', 'SITTING', ..., 'WALKING_UPSTAIRS', 'STANDING',\n",
              "       'WALKING'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "U0VWOjKrhe4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = train_model(train_X, train_y, model_name='RF', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDeHFvGihcou",
        "outputId": "769a1fc6-8060-43ae-956a-0a1a15bded79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'RF' = 0.9226331862911435\n",
            "[[537   0   0   0   0   0]\n",
            " [  0 435  56   0   0   0]\n",
            " [  0  46 486   0   0   0]\n",
            " [  0   0   0 477  11   8]\n",
            " [  0   0   0  26 354  40]\n",
            " [  0   0   0  34   7 430]]\n",
            "Recall in 'RF' = 1.0\n",
            "Precision in 'RF' = 1.0\n",
            "F1 Score in 'RF' = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_model(train_X, train_y, model_name='BAG', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gh7ambWhuzw",
        "outputId": "28d21cb4-deee-4e7a-e2ce-fa925e294040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'BAG' = 0.9039701391245334\n",
            "[[537   0   0   0   0   0]\n",
            " [  0 403  88   0   0   0]\n",
            " [  0  52 480   0   0   0]\n",
            " [  0   0   0 477  13   6]\n",
            " [  0   0   0   8 367  45]\n",
            " [  0   0   0  58  13 400]]\n",
            "Recall in 'BAG' = 1.0\n",
            "Precision in 'BAG' = 1.0\n",
            "F1 Score in 'BAG' = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = train_model(train_X, train_y, model_name='ADA', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ho8u3YziNWP",
        "outputId": "b050b41d-da03-40d6-cc66-dd85766fb23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'ADA' = 0.5310485239226331\n",
            "[[537   0   0   0   0   0]\n",
            " [  0   0 491   0   0   0]\n",
            " [  0   0 532   0   0   0]\n",
            " [  0   0   0 496   0   0]\n",
            " [  0   0   0 420   0   0]\n",
            " [  0   0   0 471   0   0]]\n",
            "Recall in 'ADA' = 1.0\n",
            "Precision in 'ADA' = 1.0\n",
            "F1 Score in 'ADA' = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = train_model(train_X, train_y, model_name='NB', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUp25uX4ibc2",
        "outputId": "b85d1604-00db-4a1d-e7a8-b35055250d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'NB' = 0.7702748557855447\n",
            "[[323 211   0   0   0   3]\n",
            " [  5 368 111   0   0   7]\n",
            " [  8  54 455   0   0  15]\n",
            " [  0   0   0 416  42  38]\n",
            " [  0   0   0  80 257  83]\n",
            " [  0   0   0   9  11 451]]\n",
            "Recall in 'NB' = 0.6048689138576779\n",
            "Precision in 'NB' = 0.9847560975609756\n",
            "F1 Score in 'NB' = 0.7494199535962879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = train_model(train_X, train_y, model_name='SVM', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuhkJeZCiiQW",
        "outputId": "0d931126-4056-4197-af61-b15b98d83d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'SVM' = 0.9504580929759077\n",
            "[[537   0   0   0   0   0]\n",
            " [  0 438  51   0   0   2]\n",
            " [  0  29 503   0   0   0]\n",
            " [  0   0   0 488   3   5]\n",
            " [  0   0   0  10 384  26]\n",
            " [  0   0   0  20   0 451]]\n",
            "Recall in 'SVM' = 1.0\n",
            "Precision in 'SVM' = 1.0\n",
            "F1 Score in 'SVM' = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = train_model(train_X, train_y, model_name='XGB', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUpgDBeSirRd",
        "outputId": "a125d0f4-7e8e-4471-9dcb-1b60b7c9cb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'XGB' = 0.9392602646759416\n",
            "[[537   0   0   0   0   0]\n",
            " [  0 426  63   0   0   2]\n",
            " [  0  30 502   0   0   0]\n",
            " [  0   0   0 487   5   4]\n",
            " [  0   0   0   9 383  28]\n",
            " [  0   0   0  32   6 433]]\n",
            "Recall in 'XGB' = 1.0\n",
            "Precision in 'XGB' = 1.0\n",
            "F1 Score in 'XGB' = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = train_model(train_X, train_y, model_name='KNN', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH9D_BGJjoAm",
        "outputId": "cf80a987-dc6f-4970-8c67-206ad326b3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy in 'KNN' = 0.9002375296912114\n",
            "[[534   2   1   0   0   0]\n",
            " [  0 388 100   0   0   3]\n",
            " [  0  37 495   0   0   0]\n",
            " [  0   0   0 484  10   2]\n",
            " [  0   0   0  44 331  45]\n",
            " [  0   0   0  38  12 421]]\n",
            "Recall in 'KNN' = 0.996268656716418\n",
            "Precision in 'KNN' = 1.0\n",
            "F1 Score in 'KNN' = 0.9981308411214954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8 = train_model(train_X, train_y, model_name='MLP', validation=(test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ikDbn--jsUG",
        "outputId": "0c704ed3-cb3b-4b75-9358-234b8062cc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.62746714\n",
            "Iteration 2, loss = 1.19476348\n",
            "Iteration 3, loss = 0.90534199\n",
            "Iteration 4, loss = 0.74026797\n",
            "Iteration 5, loss = 0.64002235\n",
            "Iteration 6, loss = 0.57059450\n",
            "Iteration 7, loss = 0.51745949\n",
            "Iteration 8, loss = 0.47126123\n",
            "Iteration 9, loss = 0.43067241\n",
            "Iteration 10, loss = 0.39658304\n",
            "Iteration 11, loss = 0.36767495\n",
            "Iteration 12, loss = 0.34079071\n",
            "Iteration 13, loss = 0.31958282\n",
            "Iteration 14, loss = 0.30046327\n",
            "Iteration 15, loss = 0.28397574\n",
            "Iteration 16, loss = 0.26819889\n",
            "Iteration 17, loss = 0.25469793\n",
            "Iteration 18, loss = 0.24222361\n",
            "Iteration 19, loss = 0.23157087\n",
            "Iteration 20, loss = 0.22005752\n",
            "Iteration 21, loss = 0.21231349\n",
            "Iteration 22, loss = 0.20306080\n",
            "Iteration 23, loss = 0.19541170\n",
            "Iteration 24, loss = 0.18810904\n",
            "Iteration 25, loss = 0.18146156\n",
            "Iteration 26, loss = 0.17505310\n",
            "Iteration 27, loss = 0.16923577\n",
            "Iteration 28, loss = 0.16281571\n",
            "Iteration 29, loss = 0.15716938\n",
            "Iteration 30, loss = 0.15196712\n",
            "Iteration 31, loss = 0.14695784\n",
            "Iteration 32, loss = 0.14314948\n",
            "Iteration 33, loss = 0.13936761\n",
            "Iteration 34, loss = 0.13587340\n",
            "Iteration 35, loss = 0.13217098\n",
            "Iteration 36, loss = 0.12777815\n",
            "Iteration 37, loss = 0.12509213\n",
            "Iteration 38, loss = 0.12204310\n",
            "Iteration 39, loss = 0.11724286\n",
            "Iteration 40, loss = 0.11483989\n",
            "Iteration 41, loss = 0.11156363\n",
            "Iteration 42, loss = 0.10998166\n",
            "Iteration 43, loss = 0.10780735\n",
            "Iteration 44, loss = 0.10438845\n",
            "Iteration 45, loss = 0.10238740\n",
            "Iteration 46, loss = 0.10105581\n",
            "Iteration 47, loss = 0.09719358\n",
            "Iteration 48, loss = 0.09575215\n",
            "Iteration 49, loss = 0.09507188\n",
            "Iteration 50, loss = 0.09207373\n",
            "Iteration 51, loss = 0.08923259\n",
            "Iteration 52, loss = 0.08914048\n",
            "Iteration 53, loss = 0.08692724\n",
            "Iteration 54, loss = 0.08580832\n",
            "Iteration 55, loss = 0.08552511\n",
            "Iteration 56, loss = 0.08383537\n",
            "Iteration 57, loss = 0.08101725\n",
            "Iteration 58, loss = 0.07932008\n",
            "Iteration 59, loss = 0.07893837\n",
            "Iteration 60, loss = 0.07830686\n",
            "Iteration 61, loss = 0.07599528\n",
            "Iteration 62, loss = 0.07615213\n",
            "Iteration 63, loss = 0.07463302\n",
            "Iteration 64, loss = 0.07264738\n",
            "Iteration 65, loss = 0.07257004\n",
            "Iteration 66, loss = 0.07166071\n",
            "Iteration 67, loss = 0.07043504\n",
            "Iteration 68, loss = 0.06996444\n",
            "Iteration 69, loss = 0.06748259\n",
            "Iteration 70, loss = 0.06756375\n",
            "Iteration 71, loss = 0.06641044\n",
            "Iteration 72, loss = 0.06545439\n",
            "Iteration 73, loss = 0.06418428\n",
            "Iteration 74, loss = 0.06410765\n",
            "Iteration 75, loss = 0.06469320\n",
            "Iteration 76, loss = 0.06243849\n",
            "Iteration 77, loss = 0.06213494\n",
            "Iteration 78, loss = 0.06053861\n",
            "Iteration 79, loss = 0.06064623\n",
            "Iteration 80, loss = 0.06029317\n",
            "Iteration 81, loss = 0.05988044\n",
            "Iteration 82, loss = 0.05947525\n",
            "Iteration 83, loss = 0.05900683\n",
            "Iteration 84, loss = 0.05864267\n",
            "Iteration 85, loss = 0.05697424\n",
            "Iteration 86, loss = 0.05696392\n",
            "Iteration 87, loss = 0.05650447\n",
            "Iteration 88, loss = 0.05575044\n",
            "Iteration 89, loss = 0.05577356\n",
            "Iteration 90, loss = 0.05476393\n",
            "Iteration 91, loss = 0.05457460\n",
            "Iteration 92, loss = 0.05437977\n",
            "Iteration 93, loss = 0.05452729\n",
            "Iteration 94, loss = 0.05314828\n",
            "Iteration 95, loss = 0.05197351\n",
            "Iteration 96, loss = 0.05227659\n",
            "Iteration 97, loss = 0.05200788\n",
            "Iteration 98, loss = 0.05216146\n",
            "Iteration 99, loss = 0.05175054\n",
            "Iteration 100, loss = 0.04943119\n",
            "Iteration 101, loss = 0.05054170\n",
            "Iteration 102, loss = 0.04965088\n",
            "Iteration 103, loss = 0.04962887\n",
            "Iteration 104, loss = 0.04960826\n",
            "Iteration 105, loss = 0.04899664\n",
            "Iteration 106, loss = 0.04866197\n",
            "Iteration 107, loss = 0.04781865\n",
            "Iteration 108, loss = 0.04680332\n",
            "Iteration 109, loss = 0.04626920\n",
            "Iteration 110, loss = 0.04701927\n",
            "Iteration 111, loss = 0.04583614\n",
            "Iteration 112, loss = 0.04700729\n",
            "Iteration 113, loss = 0.04539494\n",
            "Iteration 114, loss = 0.04660368\n",
            "Iteration 115, loss = 0.04581697\n",
            "Iteration 116, loss = 0.04431680\n",
            "Iteration 117, loss = 0.04447318\n",
            "Iteration 118, loss = 0.04404375\n",
            "Iteration 119, loss = 0.04328202\n",
            "Iteration 120, loss = 0.04448646\n",
            "Iteration 121, loss = 0.04424286\n",
            "Iteration 122, loss = 0.04280657\n",
            "Iteration 123, loss = 0.04341675\n",
            "Iteration 124, loss = 0.04246033\n",
            "Iteration 125, loss = 0.04276073\n",
            "Iteration 126, loss = 0.04121834\n",
            "Iteration 127, loss = 0.04110178\n",
            "Iteration 128, loss = 0.04169726\n",
            "Iteration 129, loss = 0.04039030\n",
            "Iteration 130, loss = 0.04235323\n",
            "Iteration 131, loss = 0.04019907\n",
            "Iteration 132, loss = 0.03995596\n",
            "Iteration 133, loss = 0.03998452\n",
            "Iteration 134, loss = 0.03923068\n",
            "Iteration 135, loss = 0.04071723\n",
            "Iteration 136, loss = 0.03974737\n",
            "Iteration 137, loss = 0.04154796\n",
            "Iteration 138, loss = 0.03975773\n",
            "Iteration 139, loss = 0.03944719\n",
            "Iteration 140, loss = 0.03955916\n",
            "Iteration 141, loss = 0.03861654\n",
            "Iteration 142, loss = 0.03929317\n",
            "Iteration 143, loss = 0.03754625\n",
            "Iteration 144, loss = 0.03678396\n",
            "Iteration 145, loss = 0.03736481\n",
            "Iteration 146, loss = 0.03711733\n",
            "Iteration 147, loss = 0.03687296\n",
            "Iteration 148, loss = 0.03787635\n",
            "Iteration 149, loss = 0.03735021\n",
            "Iteration 150, loss = 0.03645677\n",
            "Iteration 151, loss = 0.03721762\n",
            "Iteration 152, loss = 0.03578180\n",
            "Iteration 153, loss = 0.03655680\n",
            "Iteration 154, loss = 0.03533820\n",
            "Iteration 155, loss = 0.03620573\n",
            "Iteration 156, loss = 0.03603177\n",
            "Iteration 157, loss = 0.03412643\n",
            "Iteration 158, loss = 0.03528935\n",
            "Iteration 159, loss = 0.03661537\n",
            "Iteration 160, loss = 0.03741301\n",
            "Iteration 161, loss = 0.03532687\n",
            "Iteration 162, loss = 0.03518478\n",
            "Iteration 163, loss = 0.03377498\n",
            "Iteration 164, loss = 0.03687778\n",
            "Iteration 165, loss = 0.03715482\n",
            "Iteration 166, loss = 0.03512085\n",
            "Iteration 167, loss = 0.03404472\n",
            "Iteration 168, loss = 0.03359029\n",
            "Iteration 169, loss = 0.03251205\n",
            "Iteration 170, loss = 0.03376705\n",
            "Iteration 171, loss = 0.03439294\n",
            "Iteration 172, loss = 0.03409363\n",
            "Iteration 173, loss = 0.03434988\n",
            "Iteration 174, loss = 0.03316539\n",
            "Iteration 175, loss = 0.03408301\n",
            "Iteration 176, loss = 0.03194550\n",
            "Iteration 177, loss = 0.03428612\n",
            "Iteration 178, loss = 0.03206279\n",
            "Iteration 179, loss = 0.03293649\n",
            "Iteration 180, loss = 0.03298651\n",
            "Iteration 181, loss = 0.03158867\n",
            "Iteration 182, loss = 0.03181918\n",
            "Iteration 183, loss = 0.03189077\n",
            "Iteration 184, loss = 0.03130883\n",
            "Iteration 185, loss = 0.03215848\n",
            "Iteration 186, loss = 0.03213308\n",
            "Iteration 187, loss = 0.03079844\n",
            "Iteration 188, loss = 0.03326656\n",
            "Iteration 189, loss = 0.03013017\n",
            "Iteration 190, loss = 0.03007320\n",
            "Iteration 191, loss = 0.03222516\n",
            "Iteration 192, loss = 0.03142006\n",
            "Iteration 193, loss = 0.03027856\n",
            "Iteration 194, loss = 0.03016698\n",
            "Iteration 195, loss = 0.02920520\n",
            "Iteration 196, loss = 0.02986292\n",
            "Iteration 197, loss = 0.02967169\n",
            "Iteration 198, loss = 0.02975400\n",
            "Iteration 199, loss = 0.02882194\n",
            "Iteration 200, loss = 0.03025852\n",
            "Iteration 201, loss = 0.02943250\n",
            "Iteration 202, loss = 0.02936811\n",
            "Iteration 203, loss = 0.03028287\n",
            "Iteration 204, loss = 0.02907982\n",
            "Iteration 205, loss = 0.02917898\n",
            "Iteration 206, loss = 0.02787089\n",
            "Iteration 207, loss = 0.03020759\n",
            "Iteration 208, loss = 0.02841813\n",
            "Iteration 209, loss = 0.02974228\n",
            "Iteration 210, loss = 0.02874621\n",
            "Iteration 211, loss = 0.02879368\n",
            "Iteration 212, loss = 0.02779275\n",
            "Iteration 213, loss = 0.02955469\n",
            "Iteration 214, loss = 0.02774349\n",
            "Iteration 215, loss = 0.02816639\n",
            "Iteration 216, loss = 0.02830531\n",
            "Iteration 217, loss = 0.02906137\n",
            "Iteration 218, loss = 0.02775542\n",
            "Iteration 219, loss = 0.02834605\n",
            "Iteration 220, loss = 0.02856197\n",
            "Iteration 221, loss = 0.02689377\n",
            "Iteration 222, loss = 0.02623273\n",
            "Iteration 223, loss = 0.02767148\n",
            "Iteration 224, loss = 0.02738924\n",
            "Iteration 225, loss = 0.02655628\n",
            "Iteration 226, loss = 0.02746749\n",
            "Iteration 227, loss = 0.02664747\n",
            "Iteration 228, loss = 0.02689360\n",
            "Iteration 229, loss = 0.02740481\n",
            "Iteration 230, loss = 0.02621074\n",
            "Iteration 231, loss = 0.02714769\n",
            "Iteration 232, loss = 0.02769201\n",
            "Iteration 233, loss = 0.02798698\n",
            "Iteration 234, loss = 0.02808108\n",
            "Iteration 235, loss = 0.02626498\n",
            "Iteration 236, loss = 0.02762565\n",
            "Iteration 237, loss = 0.02678552\n",
            "Iteration 238, loss = 0.02541610\n",
            "Iteration 239, loss = 0.02557077\n",
            "Iteration 240, loss = 0.02493260\n",
            "Iteration 241, loss = 0.02670833\n",
            "Iteration 242, loss = 0.02607874\n",
            "Iteration 243, loss = 0.02588670\n",
            "Iteration 244, loss = 0.02584715\n",
            "Iteration 245, loss = 0.02622690\n",
            "Iteration 246, loss = 0.02567985\n",
            "Iteration 247, loss = 0.02740177\n",
            "Iteration 248, loss = 0.02514067\n",
            "Iteration 249, loss = 0.02424483\n",
            "Iteration 250, loss = 0.02504741\n",
            "Iteration 251, loss = 0.02639033\n",
            "Iteration 252, loss = 0.02697152\n",
            "Iteration 253, loss = 0.02518549\n",
            "Iteration 254, loss = 0.02469832\n",
            "Iteration 255, loss = 0.02438039\n",
            "Iteration 256, loss = 0.02561807\n",
            "Iteration 257, loss = 0.02578714\n",
            "Iteration 258, loss = 0.02696335\n",
            "Iteration 259, loss = 0.02468992\n",
            "Iteration 260, loss = 0.02648541\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Validation Accuracy in 'MLP' = 0.9457074991516796\n",
            "[[536   1   0   0   0   0]\n",
            " [  0 400  89   0   0   2]\n",
            " [  0   6 526   0   0   0]\n",
            " [  0   0   0 485   7   4]\n",
            " [  0   0   0   2 396  22]\n",
            " [  0   0   1  23   3 444]]\n",
            "Recall in 'MLP' = 0.9981378026070763\n",
            "Precision in 'MLP' = 1.0\n",
            "F1 Score in 'MLP' = 0.9990680335507922\n"
          ]
        }
      ]
    }
  ]
}